#include "hspcl64.as"
#include "NNmodule.hsp"

//メモ
/*
cccnt=1
	repeat 28
	ccnt=cnt
		repeat 13
		gsel 3
		pos 0,0
		gcopy 2,752+ccnt,271+51*cccnt+cnt,128,22
		bmpsave ""+rnd(99)+".bmp"
		loop
	loop
*/
//ここまで

	SKLALLSTR="ＫＯ術","アイテム使用強化","ガード強化","ガード性能","キノコ大好き","ジャンプ鉄人","スタミナ急速回復","スタミナ奪取","ひるみ軽減","フルチャージ","ブレ抑制","ボマー","ランナー","火事場力","火属性攻撃強化","火耐性","会心撃【属性】","回避距離ＵＰ","回避性能","回復速度","滑走強化","貫通弾・貫通矢強化","気絶耐性","鬼火纏","逆恨み","逆襲","強化持続","業物","見切り","幸運","広域化","攻めの守勢","攻撃","高速変形","剛刃研磨","散弾・拡散矢強化","死中に活","耳栓","弱点特効","集中","匠","乗り名人","植生学","心眼","水属性攻撃強化","水耐性","睡眠属性強化","睡眠耐性","精霊の加護","早食い","装填拡張","装填速度","速射強化","属性やられ耐性","体術","体力回復量ＵＰ","耐震","弾丸節約","弾導強化","地質学","挑戦者","超会心","通常弾・連射矢強化","泥雪耐性","笛吹き名人","砥石使用高速化","特殊射撃強化","毒属性強化","毒耐性","鈍器使い","納刀術","破壊王","剥ぎ取り鉄人","爆破やられ耐性","爆破属性強化","抜刀術【技】","抜刀術【力】","反動軽減","飛び込み","氷属性攻撃強化","氷耐性","不屈","風圧耐性","腹減り耐性","壁面移動","泡沫の舞","砲術","砲弾装填","防御","麻痺属性強化","麻痺耐性","満足感","陽動","雷属性攻撃強化","雷耐性","龍属性攻撃強化","龍耐性","力の解放","渾身","翔蟲使い","達人芸","NULL"



	//#N = 415676  # データの数
	//M = 512 # 1層
	//M2 = 256 # 2層
	//D = 128*22 # 入力層
	//K = 102
	N=28*13
	mlpLayerNum=4
	dim mlpLayerNode,mlpLayerNum
	mlpLayerNode=128*22,512,256,102
	
	//GPUデバイスせセット
	HCLinit
	sdim GOSEKIcapture3Setting,4096
	notesel GOSEKIcapture3Setting
	noteload "GOSEKIcapture3Setting.txt"
	noteget p1,1
	HCLSetDevice int(p1)
	HCLSetDevice 1

	//X作成
	newmod matX,CLMatrix,N,mlpLayerNode.0
	buffer 1:picload "25.png"
	memG=int64(gselToBufferFloat1(1))

	w=0
	maxmemid=int64(CLMmem(matX))
		repeat 13
		ccnt=cnt
			repeat 28
			clmemgcopy maxmemid,memG,752+cnt,271+ccnt,w
			w++
			loop
		loop
	HCLReleaseBuffer memG
	
	gsel 0
	wait 1
	title "ロード終わり"
	wait 1
	
	gosub*loadwv
    //b = np.zeros((N, M),dtype=np.float32)  # 中間層ニューロンの入力総和
    //z = np.zeros((N, M),dtype=np.float32)  # 中間層ニューロンの出力
    //b2 = np.zeros((N, M2),dtype=np.float32)  # 中間層ニューロンの入力総和
    //z2 = np.zeros((N, M2),dtype=np.float32)  # 中間層ニューロンの出力
    //a = np.zeros((N, K),dtype=np.float32)  # 出力層ニューロンの入力総和
    //y = np.zeros((N, K),dtype=np.float32)  # 出力層ニューロンの出力
	//b,zを作る
	//a,yはb,zの最後の要素に対応
		repeat mlpLayerNum-1
		newmod matB,CLMatrix,N,mlpLayerNode.(cnt+1)
		newmod matZ,CLMatrix,N,mlpLayerNode.(cnt+1)
		loop
	//Batch normの出力変数
		repeat mlpLayerNum-2
		newmod matBNB,CLMatrix,N,mlpLayerNode.(cnt+1)
		loop
	//Batch norm計算クラス＝モジュール変数
		repeat mlpLayerNum-2
		newmod BN,BatchNormalization,mlpLayerNode.(cnt+1),cnt+1,"学習後\\"
		loop

	gosub*FNNmain


	HCLdim_i32FromBuffer result,int64(CLMmem(matZ.(mlpLayerNum-2)))
	screen 0,1280,720
	color 255,0,0:boxf

	gsel 0
	title "結果処理中"
	wait 1
	w=0
		repeat 13
		ccnt=cnt
			repeat 28

			maxd=0.0
			maxi=-1
				repeat 102
				sc=FloatToDouble(result.(w*102+cnt))
				if maxd<sc{
					maxd=sc
					maxi=cnt
				}
				loop
			
			col=int(FloatToDouble(result.(w*102+101))*10000)
			col=col*255/10000
			color col,col,col
			pset 752+cnt,271+ccnt
			/*
			buffer 2,128,22
			pos 0,0
			gcopy 1,752+cnt,271+ccnt,128,22
			bmpsave "b\\"+SKLALLSTR.maxi+"\\b"+str(w)+".bmp"
			*/
			w++
			
			gsel 0
			loop
		loop


	
	HCLdim_i32FromBuffer tst,maxmemid
	w=0

	repeat 28*13
	cccnt=cnt
		buffer 5,128,22
		repeat 22
		ccnt=cnt
			repeat 128
			col=FloatToDouble(tst.w)*255.0
			col=int(col)
			w++
			color col,col,col
			pset cnt,ccnt
			loop
		loop
		bmpsave "aaaa"+cccnt+".bmp"
	loop
	stop


*FNNmain
	/*
    b = np.dot(x, w.T)  # N*M
    outb = bn1.forward(b, train_flg)
    z = ReLU(outb)

    b2 = np.dot(z, w2.T)  # N*M2
    outb2 = bn2.forward(b2, train_flg)
    z2 = ReLU(outb2)

    a = np.dot(z2, v.T)  # N*K
    amx = np.max(a, axis=1)
    amx = (amx[:] > 30.0) * (amx[:]-30.0)
    amx = amx.reshape((amx.shape[0], 1))
    a = a - amx

    expa = np.exp(a)
    wkz = np.sum(expa,axis=1)
    rwkz = 1.0 / wkz
    for n in range(rwkz.shape[0]):
        y[n,:] = expa[n,:] * rwkz[n]
	*/
	npdot matB.0,matX,matWV.0,0,0,0
		repeat mlpLayerNum-2
		//BNforwrd BNmodule変数,Matmodule変数in,Matmodule変数out,train_flg
		BNforwrd BN.cnt,matB.cnt,matBNB.cnt,0
		ReLU2 matZ.cnt,matBNB.cnt
		npdot matB.(cnt+1),matZ.cnt,matWV.(cnt+1),0,0,0
		loop
	//ここでaが求まっている。matBの最後の要素に入っている
	AToY matB.(mlpLayerNum-2),matZ.(mlpLayerNum-2)
	return


*loadwv
	exist "学習後\\WV0.npy"
	dim host_wv,strsize/4
	bload "学習後\\WV0.npy",host_wv
    //# wv を w と v に戻す
    //w = wv[0:M * D] # 中間層ニューロンへの重み
    //w = w.reshape(M, D)
    //w2= wv[M * D:M * D + M2 * M] # 中間層ニューロンへの重み
    //w2= w2.reshape(M2, M)
    //v = wv[M * D + M2 * M:] # 出力層ニューロンへの重み
    //v = v.reshape(K, M2)
	offsetread=0
		repeat mlpLayerNum-1
		sz=mlpLayerNode.cnt*mlpLayerNode.(cnt+1)*4
		newmod matWV,CLMatrix,mlpLayerNode.(cnt+1),mlpLayerNode.cnt
		HCLWriteBuffer int64(CLMmem(matWV.cnt)),host_wv,sz,0,128+offsetread
		transMat matWV.cnt
		offsetread+=sz
		loop
	return

#module
#deffunc clmemgcopy var dst,var src,int x,int y,int ccnt
	yy=720-22-y
		repeat 22
		HCLCopyBuffer dst,src,128*4,ccnt*128*22*4+cnt*128*4,((yy+cnt)*1280+x)*4
		loop
	return

#global